---
title: Situating Search
year: 2022
tags:
	- IR
	- Information Retrieval
	- Search
	- Linguistics
	- Large Language Models (LLMs)
	- Generative language models
	- Corpora linguistics
---

# Abstract

Search systems, like many other applications of machine learning, have become increasingly complex and opaque. The notions of relevance, usefulness, and trustworthiness with respect to information were already overloaded and often difficult to articulate, study, or implement. Newly surfaced proposals that aim to use large language models to generate relevant information for a user's needs pose even greater threat to transparency, provenance, and user interactions in a search system. In this perspective paper we revisit the problem of search in the larger context of information seeking and argue that removing or reducing interactions in an effort to retrieve presumably more relevant information can be detrimental to many fundamental aspects of search, including information verification, information literacy, and serendipity. In addition to providing suggestions for counteracting some of the potential problems posed by such models, we present a vision for search systems that are intelligent and effective, while also providing greater transparency and accountability.

# Links

- [DOI - ACM webpage](https://doi.org/10.1145/3498366.3505816](https://doi.org/10.1145/3498366.3505816)
- [HTML](https://dl.acm.org/doi/fullHtml/10.1145/3498366.3505816)

# BibTeX

```bib
@inproceedings{10.1145/3498366.3505816,
author = {Shah, Chirag and Bender, Emily M.},
title = {Situating Search},
year = {2022},
isbn = {9781450391863},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3498366.3505816},
doi = {10.1145/3498366.3505816},
abstract = {Search systems, like many other applications of machine learning, have become increasingly complex and opaque. The notions of relevance, usefulness, and trustworthiness with respect to information were already overloaded and often difficult to articulate, study, or implement. Newly surfaced proposals that aim to use large language models to generate relevant information for a user’s needs pose even greater threat to transparency, provenance, and user interactions in a search system. In this perspective paper we revisit the problem of search in the larger context of information seeking and argue that removing or reducing interactions in an effort to retrieve presumably more relevant information can be detrimental to many fundamental aspects of search, including information verification, information literacy, and serendipity. In addition to providing suggestions for counteracting some of the potential problems posed by such models, we present a vision for search systems that are intelligent and effective, while also providing greater transparency and accountability.},
booktitle = {Proceedings of the 2022 Conference on Human Information Interaction and Retrieval},
pages = {221–232},
numpages = {12},
keywords = {Language models, Information Seeking Strategies, Search models},
location = {Regensburg, Germany},
series = {CHIIR '22}
}
```

Copied from ACM citation export

# CCS

- Information systems → Users and interactive retrieval
- Information systems → Language models

# Keywords

- Search models
- Language models
- Information Seeking Strategies